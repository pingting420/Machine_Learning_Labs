{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SVM4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SVM1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](SVM2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a cost function:\n",
    "    \n",
    "J(w) = $\\lambda$*$||w||^2$ + $1/n$*$\\sum_{i=1}^{n}$max(0, 1-$y_i(w.x_i + b)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part is to force the magnitude of weights to get minimized - in order to maximize the worst margin\n",
    "\n",
    "$\\frac{1}{||w||^2}$\n",
    "\n",
    "This indeed means that hard margin SVM tries to minimize ∥w∥2. Due to the formulation of the SVM problem, the margin is 1/∥w∥. As such, minimizing the norm of w is geometrically equivalent to maximizing the margin. Exactly what we want!\n",
    "\n",
    "The second part is called \"Hing Loss\" and we use in the SOft margin SVM\n",
    "\n",
    "since if the training example lies outside the margin ξi will be zero and it will only be nonzero when training example falls into margin region, and since hinge loss is always nonnegative, it happens we can rephrase our problem as\n",
    "\n",
    "$max(0, 1-y_i(w.x_i + b))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if:\n",
    "\n",
    "- $y_i$*($w^Tx + b$) $\\geq$ 1:\n",
    "        The we dont have the hing loss and only want to minimize the maginitude of w\n",
    "        \n",
    "        \n",
    "- else:\n",
    "\n",
    "J(w) = $\\lambda$*$||w||^2$ + $1/n$*$\\sum_{i=1}^{n}$max(0, 1-$y_i(w.x_i + b)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradients:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if:\n",
    "- $y_i$*($w^Tx + b$) $\\geq$ 1:\n",
    "\n",
    "$\\frac{dJ}{dw_k}$ = $2\\lambda.w_k$\n",
    "        \n",
    "- else:\n",
    "\n",
    "$\\frac{dJ}{dw_k}$ = $2\\lambda w_k$ -$y_i.x_i$\n",
    "\n",
    "$\\frac{dJ}{db}$ = $-y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update rules: GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ w = w - \\alpha.dw$\n",
    "\n",
    "$ b = b - \\alpha.db$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Solving using Sequential least squares programing (SLSQP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
